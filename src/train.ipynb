{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFrsMVH94299r38EPvumDH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UTyX73ivtJJV"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from dataset import IMDbDataset\n","\n","# Load dataset\n","df = pd.read_csv(\"IMDB Dataset.csv\")\n","df = df.sample(min(5000, len(df)), random_state=42)\n","df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df['review'].tolist(),\n","    df['label'].tolist(),\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","# Tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n","\n","# Datasets\n","train_dataset = IMDbDataset(train_encodings, train_labels)\n","val_dataset = IMDbDataset(val_encodings, val_labels)\n","\n","# Model\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","\n","# Metrics\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_steps=10,\n","    learning_rate=5e-6,\n","    weight_decay=0.01,\n","    report_to=\"none\",\n","    run_name=\"bert-imdb-small\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",")\n","\n","trainer.train()\n","\n","# Save model\n","model.save_pretrained(\"results/model\")\n","tokenizer.save_pretrained(\"results/model\")\n"]}]}